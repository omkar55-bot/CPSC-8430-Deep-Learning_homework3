================================================================================
                    EVALUATION RESULTS SUMMARY
                    Spoken-SQuAD Question Answering
================================================================================

Date: October 24, 2025
Total Test Questions: 5,351

================================================================================
MAIN RESULTS TABLE
================================================================================

+-------------+----------+--------------+---------------+-------------------+
| Model       | F1 Score | Exact Match  | Training Time | Empty Predictions |
+-------------+----------+--------------+---------------+-------------------+
| Simple      | 46.04%   | 32.20%       | ~45 min       | 14 (0.26%)        |
| Medium      | 46.02%   | 32.03%       | ~1.5 hours    | 12 (0.22%)        |
| Strong      | 53.80%   | 38.70%       | ~3 hours      | 0 (0%)            |
| Boss        | 50.96%   | 35.08%       | ~12 hours     | 0 (0%)            |
+-------------+----------+--------------+---------------+-------------------+

WINNER: Strong Configuration
- Best F1: 53.80%
- Best Exact Match: 38.70%
- No empty predictions
- Most efficient in terms of performance/time ratio


================================================================================
DETAILED CONFIGURATION COMPARISON
================================================================================

┌─────────────────────────────────────────────────────────────────────────┐
│ SIMPLE CONFIGURATION                                                    │
├─────────────────────────────────────────────────────────────────────────┤
│ Model Architecture:  bert-base-chinese                                 │
│ Training Epochs:     3                                                  │
│ Batch Size:          16                                                 │
│ Learning Rate:       3e-5                                               │
│ FP16:                No                                                 │
│ Grad Accumulation:   1                                                  │
│                                                                          │
│ Results:                                                                │
│   F1 Score:          46.04%                                             │
│   Exact Match:       32.20%                                             │
│   Empty Answers:     14                                                 │
│   Avg Answer Len:    19.9 chars                                         │
└─────────────────────────────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────────────────────────────┐
│ MEDIUM CONFIGURATION                                                    │
├─────────────────────────────────────────────────────────────────────────┤
│ Model Architecture:  bert-base-chinese                                 │
│ Training Epochs:     5                                                  │
│ Batch Size:          16                                                 │
│ Learning Rate:       3e-5                                               │
│ LR Scheduler:        Linear warmup + decay                              │
│ FP16:                No                                                 │
│ Grad Accumulation:   2                                                  │
│                                                                          │
│ Results:                                                                │
│   F1 Score:          46.02%                                             │
│   Exact Match:       32.03%                                             │
│   Empty Answers:     12                                                 │
│   Avg Answer Len:    20.1 chars                                         │
│                                                                          │
│ Notes: Minimal improvement over Simple despite longer training         │
└─────────────────────────────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────────────────────────────┐
│ STRONG CONFIGURATION ★ BEST PERFORMANCE ★                               │
├─────────────────────────────────────────────────────────────────────────┤
│ Model Architecture:  hfl/chinese-electra-180g-base-discriminator       │
│ Training Epochs:     8                                                  │
│ Batch Size:          16                                                 │
│ Learning Rate:       3e-5                                               │
│ LR Scheduler:        Linear warmup + decay                              │
│ FP16:                Yes (Mixed Precision)                              │
│ Grad Accumulation:   4                                                  │
│ Dropout:             0.2                                                │
│                                                                          │
│ Results:                                                                │
│   F1 Score:          53.80% ⬆                                           │
│   Exact Match:       38.70% ⬆                                           │
│   Empty Answers:     0                                                  │
│   Avg Answer Len:    20.4 chars                                         │
│                                                                          │
│ Improvement over Simple:                                                │
│   F1: +7.76 percentage points                                           │
│   EM: +6.50 percentage points                                           │
└─────────────────────────────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────────────────────────────┐
│ BOSS CONFIGURATION (ENSEMBLE)                                           │
├─────────────────────────────────────────────────────────────────────────┤
│ Model Architecture:  hfl/chinese-electra-180g-base-discriminator       │
│ Ensemble Size:       3 models (different seeds)                        │
│ Training Epochs:     15 per model                                       │
│ Batch Size:          8                                                  │
│ Learning Rate:       5e-6 (lower)                                       │
│ LR Scheduler:        Linear warmup + decay                              │
│ FP16:                Yes (Mixed Precision)                              │
│ Grad Accumulation:   8                                                  │
│ Dropout:             0.3                                                │
│                                                                          │
│ Results:                                                                │
│   F1 Score:          50.96%                                             │
│   Exact Match:       35.08%                                             │
│   Empty Answers:     0                                                  │
│   Avg Answer Len:    21.2 chars                                         │
│                                                                          │
│ Note: Underperformed Strong despite being ensemble                     │
│       Possible reasons: over-regularization, low LR, similar models     │
└─────────────────────────────────────────────────────────────────────────┘


================================================================================
PERFORMANCE IMPROVEMENTS BREAKDOWN
================================================================================

From Simple to Medium:
  F1 Change:  -0.02% (basically no change)
  EM Change:  -0.17% (slight decrease)
  Conclusion: Just training longer with same model doesn't help much

From Simple to Strong:
  F1 Change:  +7.76% ★ SIGNIFICANT IMPROVEMENT
  EM Change:  +6.50% ★ SIGNIFICANT IMPROVEMENT
  Key factors:
    - Better model (ELECTRA vs BERT)
    - Mixed precision training
    - Better regularization
    - Longer training

From Strong to Boss:
  F1 Change:  -2.84% (decreased)
  EM Change:  -3.62% (decreased)
  Conclusion: Ensemble didn't help, possibly due to:
    - Too similar models (same architecture)
    - Over-regularization (dropout 0.3)
    - Too low learning rate (5e-6)


================================================================================
KEY HYPERPARAMETERS COMPARISON
================================================================================

                    Simple    Medium    Strong    Boss
                    ------    ------    ------    ----
Base Model:         BERT      BERT      ELECTRA   ELECTRA
Epochs:             3         5         8         15
Batch Size:         16        16        16        8
Effective Batch:    16        32        64        64
Learning Rate:      3e-5      3e-5      3e-5      5e-6
Warmup Ratio:       0.1       0.1       0.15      0.2
Weight Decay:       0.01      0.01      0.01      0.005
Dropout:            0.1       0.1       0.2       0.3
FP16:               No        No        Yes       Yes
Grad Accum:         1         2         4         8
Max Grad Norm:      1.0       1.0       1.0       0.3

Common Settings (All Models):
  - Max Length:         512 tokens
  - Doc Stride:         150 tokens
  - Max Answer Length:  30 tokens
  - Optimizer:          AdamW
  - LR Schedule:        Linear warmup + decay


================================================================================
PREPROCESSING & POSTPROCESSING IMPROVEMENTS
================================================================================

Preprocessing Improvements Implemented:
  ✓ Sliding window approach with doc_stride=150
  ✓ Answer centering in training windows
  ✓ Proper handling of long contexts (>512 tokens)
  ✓ SQuAD format data flattening
  ✓ Correct token-to-character mapping

Postprocessing Improvements Implemented:
  ✓ Validation: end_idx >= start_idx (prevents invalid spans)
  ✓ Tuned max_answer_length=30 (prevents overly long predictions)
  ✓ Best answer selection across multiple windows
  ✓ Proper text decoding and cleanup
  ✓ Top-K candidate evaluation (K=20)

Bug Fixes:
  ✓ Fixed gradient clipping with FP16 (sync_gradients check)
  ✓ Fixed model loading with safetensors format
  ✓ Fixed ensemble model loading (3 separate models)
  ✓ Fixed max_answer_length (was 100, now 30)


================================================================================
DATASET STATISTICS
================================================================================

Training Set:     33,677 questions
Validation Set:    3,434 questions
Test Set:          5,351 questions
Total:            42,462 questions

Context Lengths:  Varies (some >512 tokens, handled by sliding windows)
Answer Lengths:   Typically 5-30 characters
Question Types:   Who, What, Where, When, Why, How
Language:         Chinese (Spoken SQuAD)


================================================================================
COMPUTATIONAL RESOURCES
================================================================================

Hardware Used:
  - GPU: NVIDIA GPU with CUDA 11.8
  - RAM: Sufficient for batch processing
  - Storage: ~2GB for models and data

Training Times:
  - Simple:  ~45 minutes
  - Medium:  ~1.5 hours
  - Strong:  ~3 hours
  - Boss:    ~12 hours (3 models × 4 hours)

Model Sizes:
  - BERT-base:    ~400MB
  - ELECTRA-base: ~400MB
  - Ensemble:     ~1.2GB (3 models)


================================================================================
ANALYSIS: WHY STRONG BEAT BOSS
================================================================================

Expected: Boss (ensemble) should outperform Strong (single model)
Reality:  Strong achieved better results

Possible Explanations:

1. Model Diversity Issue
   - All 3 Boss models use same architecture
   - Only differ by random seed
   - Not enough diversity for ensemble benefit
   - Averaging similar predictions doesn't add much value

2. Hyperparameter Mismatch
   - Boss uses very low LR (5e-6 vs 3e-5)
   - Might be too conservative for proper convergence
   - Very high dropout (0.3) might hurt learning
   - Balance between regularization and performance

3. Ensemble Averaging Effect
   - Averaging logits might smooth out confident predictions
   - Strong model might make more confident correct predictions
   - Averaging reduces both correct and incorrect confidence

4. Training Time vs Performance
   - Boss trains 3x longer but performs worse
   - Diminishing returns from extended training
   - Possible overfitting despite regularization

5. Individual Model Quality
   - If individual ensemble models are weaker than Strong
   - Averaging won't magically improve them
   - Quality > Quantity principle

Lessons Learned:
  - Ensemble isn't a guaranteed improvement
  - Need diverse models (different architectures, training data, etc.)
  - Hyperparameter tuning is crucial for ensemble
  - Sometimes a well-optimized single model is better


================================================================================
RECOMMENDATIONS FOR FUTURE IMPROVEMENTS
================================================================================

To Improve Performance:

1. Model Architecture
   ✓ Try larger models (ELECTRA-large, RoBERTa-large)
   ✓ Experiment with recent architectures (DeBERTa, ALBERT)
   ✓ Try domain-specific pretrained models

2. Ensemble Strategy
   ✓ Use different model architectures (BERT + ELECTRA + RoBERTa)
   ✓ Train on different data subsets
   ✓ Use different hyperparameters for each model
   ✓ Try stacking or voting instead of averaging

3. Training Techniques
   ✓ Adversarial training for robustness
   ✓ Data augmentation (back-translation, paraphrasing)
   ✓ Curriculum learning (easy to hard examples)
   ✓ Multi-task learning (with related tasks)

4. Hyperparameter Tuning
   ✓ Grid search or Bayesian optimization
   ✓ Better learning rate scheduling
   ✓ Optimal dropout rates
   ✓ Better warmup strategies

5. Postprocessing
   ✓ Beam search for answer extraction
   ✓ Confidence calibration
   ✓ Answer validation with external knowledge
   ✓ Context-aware answer selection


================================================================================
CONCLUSION
================================================================================

The Strong configuration with ELECTRA-base model achieved the best results:
  - F1 Score: 53.80%
  - Exact Match: 38.70%
  - Reliable predictions (0 empty answers)
  - Efficient training time (~3 hours)

Key Success Factors:
  1. Better pretrained model (ELECTRA)
  2. Mixed precision training (FP16)
  3. Proper preprocessing (sliding windows)
  4. Validated postprocessing
  5. Well-tuned hyperparameters

The project successfully demonstrates:
  - Implementation of modern QA systems
  - Importance of preprocessing and postprocessing
  - Model selection impact on performance
  - Ensemble techniques (even when they don't always win)
  - Systematic experimentation and analysis

This comprehensive evaluation provides valuable insights for building
production-ready Question Answering systems.

================================================================================
END OF RESULTS SUMMARY
================================================================================
